/*
 * This Kotlin source file was generated by the Gradle 'init' task.
 */
package net.b0n541

import com.sksamuel.scrimage.ImmutableImage
import com.sksamuel.scrimage.color.GrayscaleMethod
import com.sksamuel.scrimage.nio.PngWriter
import org.jetbrains.kotlinx.dl.api.preprocessing.pipeline
import org.jetbrains.kotlinx.dl.api.summary.printSummary
import org.jetbrains.kotlinx.dl.impl.preprocessing.image.*
import org.jetbrains.kotlinx.dl.onnx.inference.ONNXModelHub
import org.jetbrains.kotlinx.dl.onnx.inference.ONNXModels
import org.jetbrains.kotlinx.dl.onnx.inference.OnnxInferenceModel
import org.jetbrains.kotlinx.dl.onnx.inference.executionproviders.ExecutionProvider
import org.jetbrains.kotlinx.dl.onnx.inference.facealignment.FaceDetectionModel
import java.awt.image.BufferedImage
import java.nio.file.Path

fun main() {


    predictEmotions()
}

private fun predictEmotions() {

    val modelHub = ONNXModelHub(Path.of("data").toFile())
    val detectionModel = ONNXModels.FaceDetection.UltraFace320.pretrainedModel(modelHub)
    detectionModel.printSummary()

    // this needs to downloaded manually, see README.md
    val emotionModel = OnnxInferenceModel("data/models/onnx/emotionrecognition/emotion-ferplus-8.onnx")
    emotionModel.initializeWith(ExecutionProvider.CPU())
    emotionModel.printSummary()

    val filePath = "data/images"
    listOf(
        "angry_man1.png",
        "angry_woman1.png",
        "happy_man1.png",
        "happy_woman1.png",
        "disgusted_man1.png",
        "disgusted_woman1.png",
        "sad_man1.png",
        "sad_woman1.png",
        "surprised_man1.png",
        "surprised_woman1.png",
        "feared_man1.png",
        "feared_woman1.png"
    ).forEach {
        predictEmotion(detectionModel, emotionModel, filePath, it)
    }
}

val preprocessing = pipeline<BufferedImage>()
    .resize {
        outputHeight = 64
        outputWidth = 64
    }
    .convert { colorMode = ColorMode.GRAYSCALE }
    .toFloatArray { }

fun predictEmotion(
    detectionModel: FaceDetectionModel,
    emotionModel: OnnxInferenceModel,
    filePath: String,
    fileName: String
) {
    println("Picture: " + fileName)

    val image = ImageConverter.toBufferedImage(Path.of(filePath + "/" + fileName).toFile())

    val faces = detectionModel.detectFaces(image)

    faces.forEach { face ->
        val croppedImage = image.getSubimage(
            (image.width * face.xMin).toInt(),
            (image.height * face.yMin).toInt(),
            (image.width * (face.xMax - face.xMin)).toInt(),
            (image.height * (face.yMax - face.yMin)).toInt()
        )

        ImmutableImage.fromAwt(croppedImage)
            .scaleTo(64, 64)
            .toGrayscale(GrayscaleMethod.AVERAGE)
            .output(
                PngWriter(),
                Path.of(filePath + "/" + fileName.substringBefore(".") + "_input." + fileName.substringAfter("."))
            )

        val modelInput = preprocessing.apply(croppedImage).first

        println("Model input: " + modelInput.joinToString())
        println("Input size: " + modelInput.size)
        println("Min: " + modelInput.min())
        println("Max: " + modelInput.max())

        val predict = emotionModel.predict(modelInput)
        println("Prediction: " + getEmotion(predict) + " " + getEmojii(predict))
        println()
    }
}

fun getEmotion(index: Int) = when (index) {
    0 -> "neutral"
    1 -> "happiness"
    2 -> "surprise"
    3 -> "sadness"
    4 -> "anger"
    5 -> "disgust"
    6 -> "fear"
    7 -> "contempt"
    else -> "unknown"
}

fun getEmojii(index: Int) = when (index) {
    0 -> "\uD83D\uDE10"
    1 -> "\uD83D\uDE03"
    2 -> "\uD83D\uDE2E"
    3 -> "\uD83D\uDE1F"
    4 -> "\uD83D\uDE21"
    5 -> "\uD83E\uDD22"
    6 -> "\uD83D\uDE31"
    7 -> "contempt"
    else -> "unknown"
}
